{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWi0Pjp_wGQR"
   },
   "source": [
    "# Download the archive at this [link](https://drive.google.com/file/d/1ayxegsMonJUd_6_NBs4MTEQ9mR7RJ3As/view?usp=sharing) and unzip it in the current folder. Install all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYyeijB60rNL",
    "outputId": "e5c5a79d-032b-4beb-e388-5ab25216aa60"
   },
   "outputs": [],
   "source": [
    "# run this if you are in colab\n",
    "!gdown --id 1ayxegsMonJUd_6_NBs4MTEQ9mR7RJ3As\n",
    "!unzip fabric-data.zip\n",
    "!pip install colorthief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh8Gnugpwao8"
   },
   "source": [
    "## Import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xq4yhVDE1QC5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection  import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from colorthief import ColorThief\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T11XuPDJwg1O"
   },
   "outputs": [],
   "source": [
    "def resize(image, dim=100):\n",
    "    try:\n",
    "        im = cv2.imread(image)\n",
    "        resized = cv2.resize(im, (dim, dim), interpolation = cv2.INTER_AREA)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return resized\n",
    "\n",
    "# training info\n",
    "n_folds=5\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Lv2AkNtO1Xxr",
    "outputId": "c128cb18-823b-441a-db42-e41c19215ef8"
   },
   "outputs": [],
   "source": [
    "# load dataset info\n",
    "df = pd.read_csv('dataset.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXS-3ust8Lng"
   },
   "outputs": [],
   "source": [
    "# dataset folders\n",
    "data_color= \"Dataset\"\n",
    "color_reference_folder='Ref/'\n",
    "ref_dominant='Ref_dominant'\n",
    "\n",
    "classi = [\"Orange\", \"White\", \"Blue\", \"Cyan\", \"Yellow\", \"Magenta\", \"Black\", \"Red\", \"Earth Brown\", \"Green\", \"Emerald Green\", \"Purple\"]\n",
    "# classi=[\"Arancione\", \"Bianco\", \"Blu\", \"Cyan\", \"Giallo\", \"Magenta\", \"Nero\", \"Rosso\", \"Terra\", \"Verde\", \"Verde_Smeraldo\", \"Viola\"]\n",
    "\n",
    "if not os.path.exists(ref_dominant):\n",
    "    os.makedirs(ref_dominant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kgv8dBmh2h0s"
   },
   "source": [
    "## Create the difference domain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sv9c7n9N9leI"
   },
   "outputs": [],
   "source": [
    "# get the images for each reference color\n",
    "for elem in os.listdir(color_reference_folder):\n",
    "    img = resize(color_reference_folder + \"/\" + elem)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    color_thief = ColorThief(color_reference_folder+\"/\"+elem)\n",
    "    dominant_color = color_thief.get_color(quality=1)\n",
    "\n",
    "    img_color = img.copy()\n",
    "    img_color[:,:,0] = dominant_color[0]\n",
    "    img_color[:,:,1] = dominant_color[1]\n",
    "    img_color[:,:,2] = dominant_color[2]\n",
    "\n",
    "    img_color = cv2.cvtColor(img_color, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.imwrite('Ref_dominant/'+ elem,img_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lRG8C7D2VF8"
   },
   "outputs": [],
   "source": [
    "# translate images into the difference domain\n",
    "dataset = []\n",
    "for index, row in df.iterrows():\n",
    "  path_img = row['image_path']\n",
    "  labels = row['color']\n",
    "  dizionario={}\n",
    "  temp=[]\n",
    "  for elem in os.listdir(ref_dominant):\n",
    "    img_dominant = cv2.imread(path_img)\n",
    "    img_ref = cv2.imread(ref_dominant+'/'+elem)\n",
    "    result = img_dominant - img_ref\n",
    "    result = (result/255).astype(np.float16)\n",
    "    temp.append(result[:,:,0])\n",
    "    temp.append(result[:,:,1])\n",
    "    temp.append(result[:,:,2])\n",
    "  temp.append(labels)\n",
    "  dataset.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ewVjkh-iWVd"
   },
   "outputs": [],
   "source": [
    "# encode classes\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(classi)\n",
    "\n",
    "x=[x[0:36] for x in dataset]\n",
    "x = np.array(x)\n",
    "x= np.moveaxis(x,1,3)\n",
    "\n",
    "y=[elem[36] for elem in dataset ]\n",
    "y = le.transform(y)\n",
    "y=np.array(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scj44Xc4ijk_"
   },
   "outputs": [],
   "source": [
    "# split and hold a part of dataset for testing\n",
    "X_hold, X_test, y_hold, y_test = train_test_split(x, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvqI9tZLjR_F"
   },
   "source": [
    "# model1.h5: lr=0.001 beta_1=0.9, beta_2=0.999, epsilon=1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnSiVWxViouq"
   },
   "outputs": [],
   "source": [
    "def model_one():\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(32, 3, 3, input_shape = (100, 100, 36), activation = 'relu'))\n",
    "\n",
    "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "  model.add(Conv2D(32, 3, 3, activation = 'relu'))\n",
    "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(128, activation = 'relu', kernel_regularizer='l2'))\n",
    "  model.add(Dense(12, activation = 'softmax'))\n",
    "\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1UDvVAZjlIt",
    "outputId": "7c69f89d-38c9-4a63-84f5-c396721bf337"
   },
   "outputs": [],
   "source": [
    "model = model_one()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_hold, y_hold, test_size=0.2, stratify=y_hold)\n",
    "\n",
    "# Defining epoch step sizes based on number of images divided by batch size\n",
    "step_train = len(X_train)//BATCH_SIZE\n",
    "step_valid = len(X_val)//BATCH_SIZE\n",
    "step_test =  len(X_test)//BATCH_SIZE\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath='Models/model1.h5',\n",
    "                                            save_weights_only=False,\n",
    "                                            monitor='val_accuracy',\n",
    "                                            mode='max',\n",
    "                                            save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "#Training fold\n",
    "history=model.fit(X_train, y_train, \n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  validation_data= (X_val, y_val),\n",
    "                  validation_steps=step_valid, \n",
    "                  epochs=50, \n",
    "                  steps_per_epoch=step_train, \n",
    "                  callbacks=[model_checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4B4puA8DmxAx"
   },
   "outputs": [],
   "source": [
    "# load trained model\n",
    "model = load_model('Models/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 834
    },
    "id": "PwkyKASRjpiV",
    "outputId": "7b28ba54-0197-4945-cdf9-293b06e4c0f5"
   },
   "outputs": [],
   "source": [
    "#Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#Evaluation model\n",
    "y_true = np.argmax(y_test , axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred ,target_names=classi , output_dict=True)\n",
    "print(classification_report(y_true, y_pred ,target_names=classi))\n",
    "df_report = pd.DataFrame(report).T\n",
    "df_report.to_csv('classification_report_model1.csv')\n",
    "\n",
    "# plot confusion matrix\n",
    "array = confusion_matrix(y_true, y_pred )\n",
    "cmatrix = pd.DataFrame(array, index = [i for i in classi],\n",
    "                columns = [i for i in classi])\n",
    "plt.figure(figsize = (10,7))\n",
    "z = sn.heatmap(cmatrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "IHSChnJIm9EG",
    "outputId": "2f35d00c-2099-44e2-a99b-2cc60781ddee"
   },
   "outputs": [],
   "source": [
    "# plot loss and validation loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNEwTDcynAp1"
   },
   "source": [
    "# model2.h5: lr=0.0001 beta_1=0.9, beta_2=0.999, epsilon=1e-08, amsgrad=False\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yM44HfHmjxTB"
   },
   "outputs": [],
   "source": [
    "def model_two():\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(32, 3, 3, input_shape = (100, 100, 36), activation = 'relu'))\n",
    "\n",
    "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "  model.add(Conv2D(32, 3, 3, activation = 'relu'))\n",
    "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(128, activation = 'relu'))\n",
    "  model.add(Dense(12, activation = 'softmax'))\n",
    "\n",
    "  opt = Adam( learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, amsgrad=False)\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xP_Jib6WnJrR",
    "outputId": "be223f16-cd4f-4671-aabe-09582199575c"
   },
   "outputs": [],
   "source": [
    "model = model_two()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_hold, y_hold, test_size=0.2, stratify=y_hold , random_state=82)\n",
    "# Defining epoch step sizes based on number of images divided by batch size\n",
    "step_train = len(X_train)//BATCH_SIZE\n",
    "step_valid = len(X_val)//BATCH_SIZE\n",
    "step_test = (len(X_test))//BATCH_SIZE\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint( filepath='Models/model2.h5',\n",
    "                                            save_weights_only=False,\n",
    "                                            monitor='val_accuracy',\n",
    "                                            mode='max',\n",
    "                                            save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "# Training fold\n",
    "history=model.fit(X_train, y_train, batch_size=BATCH_SIZE, validation_data= (X_val, y_val),validation_steps=step_valid, epochs=150, steps_per_epoch=step_train, callbacks=[model_checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIDC78dFngFx"
   },
   "outputs": [],
   "source": [
    "# load trained model\n",
    "# if you want to use the model just trained, skip this cell\n",
    "model = load_model('Models/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "id": "C0O1Y64unYH4",
    "outputId": "626bc610-b6fa-4d90-a9c9-48046dd09356"
   },
   "outputs": [],
   "source": [
    "#Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#Evaluation model\n",
    "y_true = np.argmax(y_test , axis=1)\n",
    "\n",
    "\n",
    "report = classification_report(y_true, y_pred ,target_names=classi , output_dict=True)\n",
    "print(classification_report(y_true, y_pred ,target_names=classi))\n",
    "df_report = pd.DataFrame(report).T\n",
    "df_report.to_csv('classification_report_model2.csv')\n",
    "\n",
    "# plot confusion matrix\n",
    "array = confusion_matrix(y_true, y_pred )\n",
    "cmatrix = pd.DataFrame(array, index = [i for i in classi],\n",
    "                columns = [i for i in classi])\n",
    "plt.figure(figsize = (10,7))\n",
    "z = sn.heatmap(cmatrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "-TEsnlxGn-tB",
    "outputId": "1d834648-4de6-4c3f-95ce-9814c8e8b7ec"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Xlpa7ikoie6"
   },
   "source": [
    "# model3.h5: lr=0.00001 beta_1=0.9, beta_2=0.9, epsilon=1e-08, amsgrad=False\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9rh7mNrokKQ"
   },
   "outputs": [],
   "source": [
    "def model_three():\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(32, 3, 3, input_shape = (100, 100, 36), activation = 'relu'))\n",
    "\n",
    "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "  model.add(Conv2D(32, 3, 3, activation = 'relu'))\n",
    "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(128, activation = 'relu', kernel_regularizer='l2'))\n",
    "  model.add(Dense(12, activation = 'softmax'))\n",
    "\n",
    "  opt = SGD(learning_rate=0.01, momentum=0.0, nesterov=True)\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3pnNgV_omTQ",
    "outputId": "bc9444c2-9faa-454f-f7b0-ed5e3a904d98"
   },
   "outputs": [],
   "source": [
    "model = model_three()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_hold, y_hold, test_size=0.2, stratify=y_hold)\n",
    "# Defining epoch step sizes based on number of images divided by batch size\n",
    "step_train = len(X_train)//BATCH_SIZE\n",
    "step_valid = len(X_val)//BATCH_SIZE\n",
    "step_test = (len(X_test))//BATCH_SIZE\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint( filepath='Models/model3.h5',\n",
    "                                            save_weights_only=False,\n",
    "                                            monitor='val_accuracy',\n",
    "                                            mode='max',\n",
    "                                            save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "#Training fold\n",
    "history=model.fit(X_train, y_train, batch_size=BATCH_SIZE, validation_data= (X_val, y_val),validation_steps=step_valid, epochs=200, steps_per_epoch=step_train, callbacks=[model_checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lj0zo4TsotCm"
   },
   "outputs": [],
   "source": [
    "# load trained model\n",
    "# if you want to use the model just trained, skip this cell\n",
    "model = load_model('Models/model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "id": "YtvITfY9ouoq",
    "outputId": "b450189a-d6b5-47b0-8788-5a41f3afc23f"
   },
   "outputs": [],
   "source": [
    "#Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#Evaluation model\n",
    "y_true = np.argmax(y_test , axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred ,target_names=classi , output_dict=True)\n",
    "print(classification_report(y_true, y_pred ,target_names=classi))\n",
    "df_report = pd.DataFrame(report).T\n",
    "df_report.to_csv('classification_report_model3.csv')\n",
    "\n",
    "# plot confusion matrix\n",
    "array = confusion_matrix(y_true, y_pred )\n",
    "cmatrix = pd.DataFrame(array, index = [i for i in classi],\n",
    "                columns = [i for i in classi])\n",
    "plt.figure(figsize = (10,7))\n",
    "z = sn.heatmap(cmatrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooCHVo0Lplxt"
   },
   "source": [
    "# Ensemble of three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PK6mIi-o7rD"
   },
   "outputs": [],
   "source": [
    "#Creazione ensemble\n",
    "model1 = load_model('Models/model1.h5')\n",
    "model2 = load_model('Models/model2.h5')\n",
    "model3 = load_model('Models/model3.h5')\n",
    "model_ens = [model1 ,model2,model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80hJaetXqSiv"
   },
   "outputs": [],
   "source": [
    "#Result\n",
    "results = np.zeros( (X_test.shape[0],12) ) \n",
    "for model in model_ens:\n",
    "    results = results + model.predict(X_test)\n",
    " \n",
    "results = np.argmax(results,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 958
    },
    "id": "-ti3_iulqVdF",
    "outputId": "20edce39-2552-4a20-a3f4-3faa6809c48e"
   },
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test , axis=1)\n",
    "\n",
    "print(classification_report(y_true, results ,target_names=classi))\n",
    "array = confusion_matrix(y_true, results )\n",
    "\n",
    "cmatrix = pd.DataFrame(array, index = [i for i in classi],\n",
    "                columns = [i for i in classi])\n",
    "plt.figure(figsize = (10,7))\n",
    "z = sn.heatmap(cmatrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzsCQfWQ_wfn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
