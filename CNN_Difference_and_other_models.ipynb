{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWi0Pjp_wGQR"
   },
   "source": [
    "# Download the archive at this [link](https://drive.google.com/file/d/1ayxegsMonJUd_6_NBs4MTEQ9mR7RJ3As/view?usp=sharing) and unzip it in the current folder. Install all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYyeijB60rNL",
    "outputId": "85a77be6-1651-4385-eabc-1702060265c9"
   },
   "outputs": [],
   "source": [
    "# run this if you are in colab\n",
    "!gdown --id 1ayxegsMonJUd_6_NBs4MTEQ9mR7RJ3As\n",
    "!unzip fabric-data.zip\n",
    "!pip install colorthief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh8Gnugpwao8"
   },
   "source": [
    "## Import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xq4yhVDE1QC5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection  import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from colorthief import ColorThief\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# load other models\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet152V2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.densenet import DenseNet169, DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T11XuPDJwg1O"
   },
   "outputs": [],
   "source": [
    "def resize(image, dim=100):\n",
    "    try:\n",
    "        im = cv2.imread(image)\n",
    "        resized = cv2.resize(im, (dim, dim), interpolation = cv2.INTER_AREA)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return resized\n",
    "\n",
    "# training info\n",
    "n_folds=5\n",
    "BATCH_SIZE=16\n",
    "SGD = SGD(learning_rate=0.1, momentum=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Lv2AkNtO1Xxr",
    "outputId": "f31e6df5-685b-4f99-acac-0b5b16416686"
   },
   "outputs": [],
   "source": [
    "# load dataset info\n",
    "df = pd.read_csv('dataset.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXS-3ust8Lng"
   },
   "outputs": [],
   "source": [
    "# dataset folders\n",
    "data_color= \"Dataset\"\n",
    "color_reference_folder='Ref/'\n",
    "ref_dominant='Ref_dominant'\n",
    "\n",
    "classi = [\"Orange\", \"White\", \"Blue\", \"Cyan\", \"Yellow\", \"Magenta\", \"Black\", \"Red\", \"Earth Brown\", \"Green\", \"Emerald Green\", \"Purple\"]\n",
    "# classi=[\"Arancione\", \"Bianco\", \"Blu\", \"Cyan\", \"Giallo\", \"Magenta\", \"Nero\", \"Rosso\", \"Terra\", \"Verde\", \"Verde_Smeraldo\", \"Viola\"]\n",
    "\n",
    "if not os.path.exists(ref_dominant):\n",
    "    os.makedirs(ref_dominant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kgv8dBmh2h0s"
   },
   "source": [
    "## Create the difference domain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sv9c7n9N9leI"
   },
   "outputs": [],
   "source": [
    "# get the images for each reference color\n",
    "for elem in os.listdir(color_reference_folder):\n",
    "    img = resize(color_reference_folder + \"/\" + elem)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    color_thief = ColorThief(color_reference_folder+\"/\"+elem)\n",
    "    dominant_color = color_thief.get_color(quality=1)\n",
    "\n",
    "    img_color = img.copy()\n",
    "    img_color[:,:,0] = dominant_color[0]\n",
    "    img_color[:,:,1] = dominant_color[1]\n",
    "    img_color[:,:,2] = dominant_color[2]\n",
    "\n",
    "    img_color = cv2.cvtColor(img_color, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.imwrite('Ref_dominant/'+ elem,img_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lRG8C7D2VF8"
   },
   "outputs": [],
   "source": [
    "# translate images into the difference domain\n",
    "dataset = []\n",
    "for index, row in df.iterrows():\n",
    "  path_img = row['image_path']\n",
    "  labels = row['color']\n",
    "  dizionario={}\n",
    "  temp=[]\n",
    "  for elem in os.listdir(ref_dominant):\n",
    "    img_dominant = cv2.imread(path_img)\n",
    "    img_ref = cv2.imread(ref_dominant+'/'+elem)\n",
    "    result = img_dominant - img_ref\n",
    "    result = (result/255).astype(np.float16)\n",
    "    temp.append(result[:,:,0])\n",
    "    temp.append(result[:,:,1])\n",
    "    temp.append(result[:,:,2])\n",
    "  temp.append(labels)\n",
    "  dataset.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ewVjkh-iWVd"
   },
   "outputs": [],
   "source": [
    "# encode classes\n",
    "le = LabelEncoder()\n",
    "le.fit(classi)\n",
    "\n",
    "x=[x[0:36] for x in dataset]\n",
    "x = np.array(x)\n",
    "x= np.moveaxis(x,1,3)\n",
    "\n",
    "y=[elem[36] for elem in dataset ]\n",
    "y = le.transform(y)\n",
    "y=np.array(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scj44Xc4ijk_"
   },
   "outputs": [],
   "source": [
    "# split and hold a part of dataset for testing\n",
    "X_hold, X_test, y_hold, y_test = train_test_split(x, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzsCQfWQ_wfn"
   },
   "outputs": [],
   "source": [
    "def cnn_difference():\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(32, 3, 3, input_shape = (100, 100, 36), activation = 'relu'))\n",
    "\n",
    "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "  model.add(Conv2D(32, 3, 3, activation = 'relu'))\n",
    "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(128, activation = 'relu', kernel_regularizer='l2'))\n",
    "  model.add(Dense(12, activation = 'softmax'))\n",
    "\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkmCLYeWNLFk"
   },
   "source": [
    "## ResNet50v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7WMVQUaVLcUw",
    "outputId": "d14503a1-d877-4d87-da17-e0eeff68697a"
   },
   "outputs": [],
   "source": [
    "fold = 0\n",
    "sss = StratifiedShuffleSplit(n_splits=n_folds, random_state=15 , test_size=0.2)\n",
    "acc = [0,0]\n",
    "for index_train, index_test in sss.split(x, y):\n",
    "  fold =fold+1\n",
    "  print(str(fold)+\"/\"+str(n_folds))\n",
    "  X_hold, X_test = (x[index_train],x[index_test])\n",
    "  y_hold, y_test = (y[index_train], y[index_test])\n",
    "\n",
    "\n",
    "  X_train, X_val, y_train, y_val = train_test_split(X_hold, y_hold, test_size=0.2, stratify=y_hold)\n",
    "\n",
    "\n",
    "  resnet50 = ResNet50V2(include_top=True, \n",
    "                        weights=None, \n",
    "                        input_tensor=None,\n",
    "                        input_shape = (100, 100, 36), \n",
    "                        pooling=None, \n",
    "                        classes=12,\n",
    "                        classifier_activation='softmax')\n",
    "  \n",
    "  resnet50.compile(loss='categorical_crossentropy', \n",
    "                   optimizer=SGD,\n",
    "                   metrics=['accuracy'])\n",
    "  \n",
    "  # Defining epoch step sizes based on number of images divided by batch size\n",
    "  step_train = len(X_train)//BATCH_SIZE\n",
    "  step_valid = len(X_val)//BATCH_SIZE\n",
    "  step_test = (len(X_test))//BATCH_SIZE\n",
    "  \n",
    "  model_checkpoint_callback = ModelCheckpoint( filepath=f'model_resnet50_fold{fold}.h5',\n",
    "                                              save_weights_only=False,\n",
    "                                              monitor='val_loss',\n",
    "                                              mode='max',\n",
    "                                              save_best_only=True)\n",
    "\n",
    "  early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "  #Training fold\n",
    "  history=resnet50.fit(X_train, y_train, batch_size=BATCH_SIZE, validation_data= (X_val, y_val),validation_steps=step_valid, epochs=50, steps_per_epoch=step_train, callbacks=[early_stopping_callback])\n",
    "\n",
    "    #Predict\n",
    "  y_pred = resnet50.predict(X_test)\n",
    "  y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "  #Evaluation model\n",
    "  print(\"Evaluating fold \"+str(fold))\n",
    "\n",
    "  y_true = np.argmax(y_test , axis=1)\n",
    "\n",
    "  acc_temp = accuracy_score(y_true,y_pred)\n",
    "  if acc[0] < acc_temp:\n",
    "    acc[0] = acc_temp\n",
    "    acc[1] = fold\n",
    "\n",
    "\n",
    "  report = classification_report(y_true, y_pred ,target_names=classi , output_dict=True)\n",
    "  print(classification_report(y_true, y_pred ,target_names=classi))\n",
    "  df_report = pd.DataFrame(report).T\n",
    "  df_report.to_csv(f'resnet50_report_fold{fold}.csv')\n",
    "\n",
    "  array = confusion_matrix(y_true, y_pred )\n",
    "  cmatrix = pd.DataFrame(array, index = [i for i in classi],\n",
    "                  columns = [i for i in classi])\n",
    "  plt.figure(figsize = (10,7))\n",
    "  z = sn.heatmap(cmatrix, annot=True)\n",
    "\n",
    "  print(f\"Best model is model_fold{acc[1]}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goAnMAvyO7dX"
   },
   "source": [
    "## ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Vc0afTjSO2pc",
    "outputId": "3749807b-ba2c-4d70-9fec-df20a2b8874a"
   },
   "outputs": [],
   "source": [
    "fold = 0\n",
    "sss = StratifiedShuffleSplit(n_splits=n_folds, random_state=15 , test_size=0.2)\n",
    "acc = [0,0]\n",
    "for index_train, index_test in sss.split(x, y):\n",
    "  fold =fold+1\n",
    "  print(str(fold)+\"/\"+str(n_folds))\n",
    "  X_hold, X_test = (x[index_train],x[index_test])\n",
    "  y_hold, y_test = (y[index_train], y[index_test])\n",
    "\n",
    "\n",
    "  X_train, X_val, y_train, y_val = train_test_split(X_hold, y_hold, test_size=0.2, stratify=y_hold)\n",
    "\n",
    "\n",
    "  resnet152 = ResNet152V2(include_top=True, \n",
    "                        weights=None, \n",
    "                        input_tensor=None,\n",
    "                        input_shape = (100, 100, 36), \n",
    "                        pooling=None, \n",
    "                        classes=12,\n",
    "                        classifier_activation='softmax')\n",
    "  \n",
    "  resnet152.compile(loss='categorical_crossentropy', \n",
    "                   optimizer=SGD,\n",
    "                   metrics=['accuracy'])\n",
    "  \n",
    "  # Defining epoch step sizes based on number of images divided by batch size\n",
    "  step_train = len(X_train)//BATCH_SIZE\n",
    "  step_valid = len(X_val)//BATCH_SIZE\n",
    "  step_test = (len(X_test))//BATCH_SIZE\n",
    "  \n",
    "  model_checkpoint_callback = ModelCheckpoint( filepath=f'model_resnet152_fold{fold}.h5',\n",
    "                                              save_weights_only=False,\n",
    "                                              monitor='val_loss',\n",
    "                                              mode='max',\n",
    "                                              save_best_only=True)\n",
    "\n",
    "  early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "  #Training fold\n",
    "  history=resnet152.fit(X_train, y_train, batch_size=BATCH_SIZE, validation_data= (X_val, y_val),validation_steps=step_valid, epochs=50, steps_per_epoch=step_train, callbacks=[early_stopping_callback])\n",
    "\n",
    "    #Predict\n",
    "  y_pred = resnet152.predict(X_test)\n",
    "  y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "  #Evaluation model\n",
    "  print(\"Evaluating fold \"+str(fold))\n",
    "\n",
    "  y_true = np.argmax(y_test , axis=1)\n",
    "\n",
    "  acc_temp = accuracy_score(y_true,y_pred)\n",
    "  if acc[0] < acc_temp:\n",
    "    acc[0] = acc_temp\n",
    "    acc[1] = fold\n",
    "\n",
    "\n",
    "  report = classification_report(y_true, y_pred ,target_names=classi , output_dict=True)\n",
    "  print(classification_report(y_true, y_pred ,target_names=classi))\n",
    "  df_report = pd.DataFrame(report).T\n",
    "  df_report.to_csv(f'resnet152_report_fold{fold}.csv')\n",
    "\n",
    "  array = confusion_matrix(y_true, y_pred )\n",
    "  cmatrix = pd.DataFrame(array, index = [i for i in classi],\n",
    "                  columns = [i for i in classi])\n",
    "  plt.figure(figsize = (10,7))\n",
    "  z = sn.heatmap(cmatrix, annot=True)\n",
    "\n",
    "  print(f\"Best model is model_fold{acc[1]}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW3bsc3WO-q9"
   },
   "source": [
    "## InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9cP8ZN_BO__O",
    "outputId": "9a0737b5-bb0d-4d0a-9df8-d493f30e6470"
   },
   "outputs": [],
   "source": [
    "fold = 0\n",
    "sss = StratifiedShuffleSplit(n_splits=n_folds, random_state=15 , test_size=0.2)\n",
    "acc = [0,0]\n",
    "for index_train, index_test in sss.split(x, y):\n",
    "  fold =fold+1\n",
    "  print(str(fold)+\"/\"+str(n_folds))\n",
    "  X_hold, X_test = (x[index_train],x[index_test])\n",
    "  y_hold, y_test = (y[index_train], y[index_test])\n",
    "\n",
    "\n",
    "  X_train, X_val, y_train, y_val = train_test_split(X_hold, y_hold, test_size=0.2, stratify=y_hold)\n",
    "\n",
    "\n",
    "  inception = InceptionResNetV2(include_top=True, \n",
    "                        weights=None, \n",
    "                        input_tensor=None,\n",
    "                        input_shape = (100, 100, 36), \n",
    "                        pooling=None, \n",
    "                        classes=12,\n",
    "                        classifier_activation='softmax')\n",
    "  \n",
    "  inception.compile(loss='categorical_crossentropy', \n",
    "                   optimizer=SGD,\n",
    "                   metrics=['accuracy'])\n",
    "  \n",
    "  # Defining epoch step sizes based on number of images divided by batch size\n",
    "  step_train = len(X_train)//BATCH_SIZE\n",
    "  step_valid = len(X_val)//BATCH_SIZE\n",
    "  step_test = (len(X_test))//BATCH_SIZE\n",
    "  \n",
    "  model_checkpoint_callback = ModelCheckpoint( filepath=f'model_inception_fold{fold}.h5',\n",
    "                                              save_weights_only=False,\n",
    "                                              monitor='val_loss',\n",
    "                                              mode='max',\n",
    "                                              save_best_only=True)\n",
    "\n",
    "  early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "  #Training fold\n",
    "  history=inception.fit(X_train, y_train, batch_size=BATCH_SIZE, validation_data= (X_val, y_val),validation_steps=step_valid, epochs=50, steps_per_epoch=step_train, callbacks=[early_stopping_callback])\n",
    "\n",
    "    #Predict\n",
    "  y_pred = inception.predict(X_test)\n",
    "  y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "  #Evaluation model\n",
    "  print(\"Evaluating fold \"+str(fold))\n",
    "\n",
    "  y_true = np.argmax(y_test , axis=1)\n",
    "\n",
    "  acc_temp = accuracy_score(y_true,y_pred)\n",
    "  if acc[0] < acc_temp:\n",
    "    acc[0] = acc_temp\n",
    "    acc[1] = fold\n",
    "\n",
    "\n",
    "  report = classification_report(y_true, y_pred ,target_names=classi , output_dict=True)\n",
    "  print(classification_report(y_true, y_pred ,target_names=classi))\n",
    "  df_report = pd.DataFrame(report).T\n",
    "  df_report.to_csv(f'inception_report_fold{fold}.csv')\n",
    "\n",
    "  array = confusion_matrix(y_true, y_pred )\n",
    "  cmatrix = pd.DataFrame(array, index = [i for i in classi],\n",
    "                  columns = [i for i in classi])\n",
    "  plt.figure(figsize = (10,7))\n",
    "  z = sn.heatmap(cmatrix, annot=True)\n",
    "\n",
    "  print(f\"Best model is model_fold{acc[1]}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtN_-wTnPBkK"
   },
   "source": [
    "## DenseNet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xj9svqg7PDF1",
    "outputId": "bebc13eb-ee14-4316-ec9a-574324aaf122"
   },
   "outputs": [],
   "source": [
    "fold = 0\n",
    "sss = StratifiedShuffleSplit(n_splits=n_folds, random_state=15 , test_size=0.2)\n",
    "acc = [0,0]\n",
    "for index_train, index_test in sss.split(x, y):\n",
    "  fold =fold+1\n",
    "  print(str(fold)+\"/\"+str(n_folds))\n",
    "  X_hold, X_test = (x[index_train],x[index_test])\n",
    "  y_hold, y_test = (y[index_train], y[index_test])\n",
    "\n",
    "\n",
    "  X_train, X_val, y_train, y_val = train_test_split(X_hold, y_hold, test_size=0.2, stratify=y_hold)\n",
    "\n",
    "\n",
    "  densenet169 = DenseNet169(include_top=True, \n",
    "                        weights=None, \n",
    "                        input_tensor=None,\n",
    "                        input_shape = (100, 100, 36), \n",
    "                        pooling=None, \n",
    "                        classes=12)\n",
    "  \n",
    "  densenet169.compile(loss='categorical_crossentropy', \n",
    "                   optimizer=SGD,\n",
    "                   metrics=['accuracy'])\n",
    "  \n",
    "  # Defining epoch step sizes based on number of images divided by batch size\n",
    "  step_train = len(X_train)//BATCH_SIZE\n",
    "  step_valid = len(X_val)//BATCH_SIZE\n",
    "  step_test = (len(X_test))//BATCH_SIZE\n",
    "  \n",
    "  model_checkpoint_callback = ModelCheckpoint( filepath=f'model_densenet169_fold{fold}.h5',\n",
    "                                              save_weights_only=False,\n",
    "                                              monitor='val_loss',\n",
    "                                              mode='max',\n",
    "                                              save_best_only=True)\n",
    "\n",
    "  early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "  #Training fold\n",
    "  history=densenet169.fit(X_train, y_train, batch_size=BATCH_SIZE, validation_data= (X_val, y_val),validation_steps=step_valid, epochs=50, steps_per_epoch=step_train, callbacks=[early_stopping_callback])\n",
    "\n",
    "    #Predict\n",
    "  y_pred = densenet169.predict(X_test)\n",
    "  y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "  #Evaluation model\n",
    "  print(\"Evaluating fold \"+str(fold))\n",
    "\n",
    "  y_true = np.argmax(y_test , axis=1)\n",
    "\n",
    "  acc_temp = accuracy_score(y_true,y_pred)\n",
    "  if acc[0] < acc_temp:\n",
    "    acc[0] = acc_temp\n",
    "    acc[1] = fold\n",
    "\n",
    "\n",
    "  report = classification_report(y_true, y_pred ,target_names=classi , output_dict=True)\n",
    "  print(classification_report(y_true, y_pred ,target_names=classi))\n",
    "  df_report = pd.DataFrame(report).T\n",
    "  df_report.to_csv(f'densenet169_report_fold{fold}.csv')\n",
    "\n",
    "  array = confusion_matrix(y_true, y_pred )\n",
    "  cmatrix = pd.DataFrame(array, index = [i for i in classi],\n",
    "                  columns = [i for i in classi])\n",
    "  plt.figure(figsize = (10,7))\n",
    "  z = sn.heatmap(cmatrix, annot=True)\n",
    "\n",
    "  print(f\"Best model is model_fold{acc[1]}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmjmCul2PDin"
   },
   "source": [
    "## DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0oLYEYjFPEfu",
    "outputId": "5210de37-c723-4a93-8456-1c4e890c2e40"
   },
   "outputs": [],
   "source": [
    "fold = 0\n",
    "sss = StratifiedShuffleSplit(n_splits=n_folds, random_state=15 , test_size=0.2)\n",
    "acc = [0,0]\n",
    "for index_train, index_test in sss.split(x, y):\n",
    "  fold =fold+1\n",
    "  print(str(fold)+\"/\"+str(n_folds))\n",
    "  X_hold, X_test = (x[index_train],x[index_test])\n",
    "  y_hold, y_test = (y[index_train], y[index_test])\n",
    "\n",
    "\n",
    "  X_train, X_val, y_train, y_val = train_test_split(X_hold, y_hold, test_size=0.2, stratify=y_hold)\n",
    "\n",
    "\n",
    "  densenet201 = DenseNet201(include_top=True, \n",
    "                        weights=None, \n",
    "                        input_tensor=None,\n",
    "                        input_shape = (100, 100, 36), \n",
    "                        pooling=None, \n",
    "                        classes=12)\n",
    "  \n",
    "  densenet201.compile(loss='categorical_crossentropy', \n",
    "                   optimizer=SGD,\n",
    "                   metrics=['accuracy'])\n",
    "  \n",
    "  # Defining epoch step sizes based on number of images divided by batch size\n",
    "  step_train = len(X_train)//BATCH_SIZE\n",
    "  step_valid = len(X_val)//BATCH_SIZE\n",
    "  step_test = (len(X_test))//BATCH_SIZE\n",
    "  \n",
    "  model_checkpoint_callback = ModelCheckpoint( filepath=f'model_densenet201_fold{fold}.h5',\n",
    "                                              save_weights_only=False,\n",
    "                                              monitor='val_loss',\n",
    "                                              mode='max',\n",
    "                                              save_best_only=True)\n",
    "\n",
    "  early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "  #Training fold\n",
    "  history=densenet201.fit(X_train, y_train, batch_size=BATCH_SIZE, validation_data= (X_val, y_val),validation_steps=step_valid, epochs=50, steps_per_epoch=step_train, callbacks=[early_stopping_callback])\n",
    "\n",
    "    #Predict\n",
    "  y_pred = densenet201.predict(X_test)\n",
    "  y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "  #Evaluation model\n",
    "  print(\"Evaluating fold \"+str(fold))\n",
    "\n",
    "  y_true = np.argmax(y_test , axis=1)\n",
    "\n",
    "  acc_temp = accuracy_score(y_true,y_pred)\n",
    "  if acc[0] < acc_temp:\n",
    "    acc[0] = acc_temp\n",
    "    acc[1] = fold\n",
    "\n",
    "\n",
    "  report = classification_report(y_true, y_pred ,target_names=classi , output_dict=True)\n",
    "  print(classification_report(y_true, y_pred ,target_names=classi))\n",
    "  df_report = pd.DataFrame(report).T\n",
    "  df_report.to_csv(f'densenet201_report_fold{fold}.csv')\n",
    "\n",
    "  array = confusion_matrix(y_true, y_pred )\n",
    "  cmatrix = pd.DataFrame(array, index = [i for i in classi],\n",
    "                  columns = [i for i in classi])\n",
    "  plt.figure(figsize = (10,7))\n",
    "  z = sn.heatmap(cmatrix, annot=True)\n",
    "\n",
    "  print(f\"Best model is model_fold{acc[1]}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBmqxiGQwTe9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
